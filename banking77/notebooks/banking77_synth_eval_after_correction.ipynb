{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3b95fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.60% (2729/3080)\n",
      "Accuracy: 89.51% (2757/3080)\n"
     ]
    }
   ],
   "source": [
    "from utils import measure_accuracy, read_jsonl\n",
    "\n",
    "inference_file = '/Users/ryanarman/code/lab/banking77/notebooks/data/system_prompt_v2_lora_results_2897.jsonl'\n",
    "inference_data = read_jsonl(inference_file)\n",
    "accuracy, correct, total, errors, incorrect_list = measure_accuracy(inference_data)\n",
    "\n",
    "inference_file_corrected = '/Users/ryanarman/code/lab/banking77/notebooks/data/system_prompt_v2_improved_train_results_3015.jsonl'\n",
    "inference_data = read_jsonl(inference_file_corrected)\n",
    "accuracy_corrected, correct_corrected, total_corrected, errors_corrected, incorrect_list_corrected = measure_accuracy(inference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12e3438f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351 323\n"
     ]
    }
   ],
   "source": [
    "print(len(incorrect_list),  len(incorrect_list_corrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "415771de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_most_common_pairs(incorrect_list):\n",
    "    wihout_index = [sorted([item[1], item[2]]) for item in incorrect_list]\n",
    "    wihout_index_str = [f'{item[0]}-{item[1]}' for item in wihout_index]\n",
    "    cnt = Counter(wihout_index_str)\n",
    "    most_common_items = cnt.most_common(10)\n",
    "    most_common_pairs = [item[0] for item in most_common_items]\n",
    "    return cnt, most_common_pairs\n",
    "\n",
    "pairs_count, most_common_pairs = get_most_common_pairs(incorrect_list)\n",
    "pairs_count_corrected, most_common_pairs_corrected = get_most_common_pairs(incorrect_list_corrected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f94de850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 169)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs_count), len(pairs_count_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b1ee34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['33-36',\n",
       " '11-12',\n",
       " '48-66',\n",
       " '25-27',\n",
       " '5-67',\n",
       " '7-35',\n",
       " '56-64',\n",
       " '5-66',\n",
       " '16-28',\n",
       " '16-22']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490167b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "['33-36', '11-12', '48-66', '25-27', '5-67', '7-35', '56-64', '5-66', '16-28', '16-22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "['48-66','66-67', '5-66', '56-65', '7-35', '5-67', '21-38', '51-53', '11-12', '9-24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d58fba2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['33-36',\n",
       " '25-27',\n",
       " '11-12',\n",
       " '5-66',\n",
       " '48-66',\n",
       " '16-22',\n",
       " '16-28',\n",
       " '7-35',\n",
       " '56-64',\n",
       " '48-67']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_pairs_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cdba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "['33-36', '25-27', '11-12', '5-66', '48-66', '16-22', '16-28', '7-35', '56-64', '48-67']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24e5cee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows with incorrect pairs for 33-36\n",
      "[247, 250, 252, 255, 264, 265, 268, 271, 276, 410, 428]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rows with incorrect pairs for 11-12\n",
      "[3, 5, 9, 11, 22, 32, 281, 305, 312]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rows with incorrect pairs for 48-66\n",
      "[842, 851, 861, 866, 867, 868, 878, 1862, 1867]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rows with incorrect pairs for 25-27\n",
      "[1721, 1726, 1730, 1739, 1754, 1755, 1756, 1758]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rows with incorrect pairs for 5-67\n",
      "[2048, 2053, 2065, 2682, 2685, 2691, 2708]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rows with incorrect pairs for 7-35\n",
      "[2160, 2173, 2176, 2178, 2190, 2196, 2314]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rows with incorrect pairs for 56-64\n",
      "[602, 614, 629, 632, 2209, 2212]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rows with incorrect pairs for 5-66\n",
      "[840, 864, 2686, 2687, 2688, 2716]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rows with incorrect pairs for 16-28\n",
      "[1088, 1096, 1101, 1106, 1501, 1504]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "rows with incorrect pairs for 16-22\n",
      "[1100, 1103, 1107, 1110, 1112, 1414]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for pair in most_common_pairs:\n",
    "    pair_split = pair.split('-')\n",
    "    p1 = (int(pair_split[0]), int(pair_split[1]))\n",
    "    p2 = (int(pair_split[1]), int(pair_split[0]))\n",
    "\n",
    "    index_list_of_incorrect_pairs = []\n",
    "    for item in incorrect_list:\n",
    "        if item[1:] == p1 or item[1:] == p2:\n",
    "            # print(item)\n",
    "            index_list_of_incorrect_pairs.append(item[0])\n",
    "\n",
    "\n",
    "    print(f\"rows with incorrect pairs for {pair}\")\n",
    "    print(index_list_of_incorrect_pairs)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fedf38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "MISCLASSIFICATION PATTERN ANALYSIS\n",
      "========================================================================================================================\n",
      "\n",
      "1. PAIRS THAT PERSIST ACROSS ALL THREE SETS (Core Confusion Pairs):\n",
      "   ['11-12', '48-66', '5-66', '7-35']\n",
      "   Count: 4\n",
      "   These are the most fundamental confusion pairs that appear regardless of dataset or model state.\n",
      "\n",
      "2. PAIRS IN VALIDATION BUT NOT IN TEST SETS (Validation-Specific Issues):\n",
      "   ['21-38', '51-53', '56-65', '66-67', '9-24']\n",
      "   Count: 5\n",
      "   These pairs were problematic in validation but may have been addressed or don't appear in test sets.\n",
      "\n",
      "3. PAIRS IN TEST SETS BUT NOT IN VALIDATION (Test-Specific Issues):\n",
      "   ['16-22', '16-28', '25-27', '33-36', '48-67', '56-64']\n",
      "   Count: 6\n",
      "   These pairs are problematic in test sets but weren't top issues in validation.\n",
      "\n",
      "4. PAIRS IN CORRECTED TEST BUT NOT ORIGINAL TEST (New Issues After Correction):\n",
      "   ['48-67']\n",
      "   Count: 1\n",
      "   These pairs became more problematic after fine-tuning corrections.\n",
      "\n",
      "5. PAIRS IN ORIGINAL TEST BUT NOT CORRECTED TEST (Fixed Issues):\n",
      "   ['5-67']\n",
      "   Count: 1\n",
      "   These pairs were problematic in original test but improved after correction.\n",
      "\n",
      "6. OVERLAP BETWEEN VALIDATION AND TEST SETS:\n",
      "   ['11-12', '48-66', '5-66', '5-67', '7-35']\n",
      "   Count: 5\n",
      "   Percentage of validation pairs that appear in test: 50.0%\n",
      "\n",
      "========================================================================================================================\n",
      "KEY INSIGHTS:\n",
      "========================================================================================================================\n",
      "\n",
      "A. PERSISTENT CONFUSION PAIRS (appear in all sets):\n",
      "   11-12: card_arrival <-> card_delivery_estimate\n",
      "   48-66: pending_transfer <-> transfer_not_received_by_recipient\n",
      "   5-66: balance_not_updated_after_bank_transfer <-> transfer_not_received_by_recipient\n",
      "   7-35: beneficiary_not_allowed <-> failed_transfer\n",
      "\n",
      "B. TRANSFER-RELATED CONFUSIONS:\n",
      "   Found 9 transfer-related confusion pairs\n",
      "   25-27: declined_card_payment <-> declined_transfer\n",
      "   48-66: pending_transfer <-> transfer_not_received_by_recipient\n",
      "   48-67: pending_transfer <-> transfer_timing\n",
      "   5-66: balance_not_updated_after_bank_transfer <-> transfer_not_received_by_recipient\n",
      "   5-67: balance_not_updated_after_bank_transfer <-> transfer_timing\n",
      "   56-64: top_up_by_bank_transfer_charge <-> transfer_fee_charged\n",
      "   56-65: top_up_by_bank_transfer_charge <-> transfer_into_account\n",
      "   66-67: transfer_not_received_by_recipient <-> transfer_timing\n",
      "   7-35: beneficiary_not_allowed <-> failed_transfer\n",
      "\n",
      "C. CARD-RELATED CONFUSIONS:\n",
      "   Found 7 card-related confusion pairs\n",
      "   11-12: card_arrival <-> card_delivery_estimate\n",
      "   16-22: card_payment_not_recognised <-> compromised_card\n",
      "   16-28: card_payment_not_recognised <-> direct_debit_payment_not_recognised\n",
      "   21-38: change_pin <-> get_physical_card\n",
      "   25-27: declined_card_payment <-> declined_transfer\n",
      "   51-53: Refund_not_showing_up <-> reverted_card_payment?\n",
      "   9-24: card_about_to_expire <-> country_support\n",
      "\n",
      "========================================================================================================================\n",
      "INTERPRETATION:\n",
      "========================================================================================================================\n",
      "\n",
      "1. PERSISTENT PAIRS (4 pairs): These are the most critical confusion pairs that \n",
      "   appear across all datasets. They represent fundamental semantic overlaps that need targeted training.\n",
      "\n",
      "2. VALIDATION vs TEST DIFFERENCES: The validation set identified some pairs that don't appear as \n",
      "   frequently in test sets, suggesting either:\n",
      "   - Validation set has different distribution\n",
      "   - Some issues were partially addressed\n",
      "   - Test set has different challenging pairs\n",
      "\n",
      "3. CORRECTION IMPACT: Comparing original vs corrected test shows:\n",
      "   - Some pairs improved (fixed_after_correction: ['5-67'])\n",
      "   - Some pairs got worse (new_after_correction: ['48-67'])\n",
      "   - This suggests fine-tuning may have over-corrected some issues while creating new ones\n",
      "\n",
      "4. TRANSFER CONFUSIONS: Many persistent pairs involve transfer-related intents, indicating this \n",
      "   is a particularly challenging domain with subtle distinctions.\n",
      "\n",
      "5. RECOMMENDATION: Focus training data augmentation on persistent pairs, especially transfer-related\n",
      "   ones, with more diverse examples highlighting the nuanced differences.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis of misclassification patterns across validation, corrected test, and original test sets\n",
    "\n",
    "validation_top10 = ['48-66','66-67', '5-66', '56-65', '7-35', '5-67', '21-38', '51-53', '11-12', '9-24']\n",
    "corrected_test_top10 = ['33-36', '25-27', '11-12', '5-66', '48-66', '16-22', '16-28', '7-35', '56-64', '48-67']\n",
    "original_test_top10 = ['33-36', '11-12', '48-66', '25-27', '5-67', '7-35', '56-64', '5-66', '16-28', '16-22']\n",
    "\n",
    "# Convert to sets for easier comparison\n",
    "val_set = set(validation_top10)\n",
    "corrected_set = set(corrected_test_top10)\n",
    "original_set = set(original_test_top10)\n",
    "\n",
    "print(\"=\"*120)\n",
    "print(\"MISCLASSIFICATION PATTERN ANALYSIS\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "print(\"\\n1. PAIRS THAT PERSIST ACROSS ALL THREE SETS (Core Confusion Pairs):\")\n",
    "persistent_pairs = val_set & corrected_set & original_set\n",
    "print(f\"   {sorted(persistent_pairs)}\")\n",
    "print(f\"   Count: {len(persistent_pairs)}\")\n",
    "print(f\"   These are the most fundamental confusion pairs that appear regardless of dataset or model state.\")\n",
    "\n",
    "print(\"\\n2. PAIRS IN VALIDATION BUT NOT IN TEST SETS (Validation-Specific Issues):\")\n",
    "val_only = val_set - corrected_set - original_set\n",
    "print(f\"   {sorted(val_only)}\")\n",
    "print(f\"   Count: {len(val_only)}\")\n",
    "print(f\"   These pairs were problematic in validation but may have been addressed or don't appear in test sets.\")\n",
    "\n",
    "print(\"\\n3. PAIRS IN TEST SETS BUT NOT IN VALIDATION (Test-Specific Issues):\")\n",
    "test_only = (corrected_set | original_set) - val_set\n",
    "print(f\"   {sorted(test_only)}\")\n",
    "print(f\"   Count: {len(test_only)}\")\n",
    "print(f\"   These pairs are problematic in test sets but weren't top issues in validation.\")\n",
    "\n",
    "print(\"\\n4. PAIRS IN CORRECTED TEST BUT NOT ORIGINAL TEST (New Issues After Correction):\")\n",
    "new_after_correction = corrected_set - original_set\n",
    "print(f\"   {sorted(new_after_correction)}\")\n",
    "print(f\"   Count: {len(new_after_correction)}\")\n",
    "print(f\"   These pairs became more problematic after fine-tuning corrections.\")\n",
    "\n",
    "print(\"\\n5. PAIRS IN ORIGINAL TEST BUT NOT CORRECTED TEST (Fixed Issues):\")\n",
    "fixed_after_correction = original_set - corrected_set\n",
    "print(f\"   {sorted(fixed_after_correction)}\")\n",
    "print(f\"   Count: {len(fixed_after_correction)}\")\n",
    "print(f\"   These pairs were problematic in original test but improved after correction.\")\n",
    "\n",
    "print(\"\\n6. OVERLAP BETWEEN VALIDATION AND TEST SETS:\")\n",
    "val_test_overlap = (val_set & (corrected_set | original_set))\n",
    "print(f\"   {sorted(val_test_overlap)}\")\n",
    "print(f\"   Count: {len(val_test_overlap)}\")\n",
    "print(f\"   Percentage of validation pairs that appear in test: {len(val_test_overlap)/len(val_set)*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "# Get label names for context\n",
    "system_message = inference_data[0]['messages'][0]['content'] if len(inference_data) > 0 else \"\"\n",
    "\n",
    "def get_label_name(label_id, system_message):\n",
    "    \"\"\"Extract label name for a given ID from system message.\"\"\"\n",
    "    import re\n",
    "    pattern = rf'{label_id}:\\s*([^\\n]+)'\n",
    "    match = re.search(pattern, system_message)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return f\"Unknown_{label_id}\"\n",
    "\n",
    "print(\"\\nA. PERSISTENT CONFUSION PAIRS (appear in all sets):\")\n",
    "for pair in sorted(persistent_pairs):\n",
    "    id1, id2 = map(int, pair.split('-'))\n",
    "    name1 = get_label_name(id1, system_message)\n",
    "    name2 = get_label_name(id2, system_message)\n",
    "    print(f\"   {pair}: {name1} <-> {name2}\")\n",
    "\n",
    "print(\"\\nB. TRANSFER-RELATED CONFUSIONS:\")\n",
    "transfer_pairs = [p for p in (val_set | corrected_set | original_set) \n",
    "                  if any('transfer' in get_label_name(int(p.split('-')[i]), system_message).lower() \n",
    "                         for i in [0,1])]\n",
    "print(f\"   Found {len(transfer_pairs)} transfer-related confusion pairs\")\n",
    "for pair in sorted(transfer_pairs)[:10]:\n",
    "    id1, id2 = map(int, pair.split('-'))\n",
    "    name1 = get_label_name(id1, system_message)\n",
    "    name2 = get_label_name(id2, system_message)\n",
    "    print(f\"   {pair}: {name1} <-> {name2}\")\n",
    "\n",
    "print(\"\\nC. CARD-RELATED CONFUSIONS:\")\n",
    "card_pairs = [p for p in (val_set | corrected_set | original_set) \n",
    "              if any('card' in get_label_name(int(p.split('-')[i]), system_message).lower() \n",
    "                     for i in [0,1])]\n",
    "print(f\"   Found {len(card_pairs)} card-related confusion pairs\")\n",
    "for pair in sorted(card_pairs)[:10]:\n",
    "    id1, id2 = map(int, pair.split('-'))\n",
    "    name1 = get_label_name(id1, system_message)\n",
    "    name2 = get_label_name(id2, system_message)\n",
    "    print(f\"   {pair}: {name1} <-> {name2}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*120)\n",
    "persistent_count = len(persistent_pairs)\n",
    "print(f\"\"\"\n",
    "1. PERSISTENT PAIRS ({persistent_count} pairs): These are the most critical confusion pairs that \n",
    "   appear across all datasets. They represent fundamental semantic overlaps that need targeted training.\n",
    "\n",
    "2. VALIDATION vs TEST DIFFERENCES: The validation set identified some pairs that don't appear as \n",
    "   frequently in test sets, suggesting either:\n",
    "   - Validation set has different distribution\n",
    "   - Some issues were partially addressed\n",
    "   - Test set has different challenging pairs\n",
    "\n",
    "3. CORRECTION IMPACT: Comparing original vs corrected test shows:\n",
    "   - Some pairs improved (fixed_after_correction: {sorted(fixed_after_correction)})\n",
    "   - Some pairs got worse (new_after_correction: {sorted(new_after_correction)})\n",
    "   - This suggests fine-tuning may have over-corrected some issues while creating new ones\n",
    "\n",
    "4. TRANSFER CONFUSIONS: Many persistent pairs involve transfer-related intents, indicating this \n",
    "   is a particularly challenging domain with subtle distinctions.\n",
    "\n",
    "5. RECOMMENDATION: Focus training data augmentation on persistent pairs, especially transfer-related\n",
    "   ones, with more diverse examples highlighting the nuanced differences.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e4f1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oumi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
