# FFT config for Qwen3 4B.
# Some param values are referenced from:
# https://github.com/pytorch/torchtune/blob/main/recipes/configs/qwen3/4B_full.yaml
#
# Requirements:
#   - Log into WandB (`wandb login`) or disable `enable_wandb`
#
# Usage:
#   oumi distributed torchrun -m oumi train -c oumi://configs/recipes/qwen3/sft/4b_full/train.yaml
#
# See Also:
#   - Documentation: https://oumi.ai/docs/en/latest/user_guides/train/train.html
#   - Config class: oumi.core.configs.TrainingConfig
#   - Config source: https://github.com/oumi-ai/oumi/blob/main/src/oumi/core/configs/training_config.py
#   - Other training configs: configs/**/*train.yaml

model:
  model_name: Qwen/Qwen3-4B-Instruct-2507
  model_max_length: 32768
  torch_dtype_str: bfloat16
  attn_implementation: sdpa
  trust_remote_code: true

data:
  # NOTE: These paths MUST be provided via submit_training_rsync.sh script arguments.
  # The script will override these placeholders with actual paths.
  train:
    datasets:
    - dataset_name: text_sft
      dataset_path: REQUIRED_VIA_SCRIPT  # Overridden by --data.train.datasets.0.dataset_path
    collator_name: "text_completions_only_with_padding"
    collator_kwargs:
      # Mark where the assistant's answer (abstract) starts
      response_template: "<|im_start|>assistant\n"
      # Mark where the user turn starts
      instruction_template: "<|im_start|>user\n"
    target_col: "messages"
    seed: 42

  validation:
    datasets:
    - dataset_name: text_sft
      dataset_path: REQUIRED_VIA_SCRIPT  # Overridden by --data.validation.datasets.0.dataset_path
    collator_name: "text_completions_only_with_padding"
    collator_kwargs:
      response_template: "<|im_start|>assistant\n"
      instruction_template: "<|im_start|>user\n"
    target_col: "messages"
    seed: 42

training:
  trainer_type: TRL_SFT
  # NOTE: output_dir and run_name will be overridden by submit_training_rsync.sh
  # to include the job ID (e.g., output/banking77_qwen3_4b_full_12345)
  output_dir: REQUIRED_VIA_SCRIPT  # Overridden by --training.output_dir
  run_name: "REQUIRED_VIA_SCRIPT"  # Overridden by --training.run_name
  
  num_train_epochs: 2
  
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 2
  # Adjusted for 8 GPUs: batch_size=1, grad_accum=2 â†’ effective batch=16 (same as 1 GPU)
  
  learning_rate: 4.0e-05
  lr_scheduler_type: cosine
  warmup_ratio: 0.05
  optimizer: adamw_torch_fused
  max_grad_norm: 1.0
  
  enable_gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: false
  
  save_steps: 100
  eval_steps: 100
  eval_strategy: "steps"
  logging_steps: 10
  
  dataloader_num_workers: auto
  dataloader_prefetch_factor: 32
  empty_device_cache_steps: 50
  include_performance_metrics: true
  
  enable_wandb: True
  enable_mlflow: True
  
  ddp_find_unused_parameters: False
  compile: False

fsdp:
  enable_fsdp: True
  forward_prefetch: True
  sharding_strategy: "HYBRID_SHARD"
  auto_wrap_policy: "TRANSFORMER_BASED_WRAP"
  transformer_layer_cls: "Qwen3DecoderLayer"
